{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielZanotti/Desafio_ImersaoIAlura/blob/main/ImersaoIAlura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D0YS_ihzutl"
      },
      "source": [
        "Instalando o SDK do Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zCcoQJsJuARp"
      },
      "outputs": [],
      "source": [
        "#Instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFHxM2KCzyp-"
      },
      "source": [
        "Configurando API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JiS2dq5_xHMa"
      },
      "outputs": [],
      "source": [
        "#Configurações iniciais\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import random\n",
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('secret_key')\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rfbkuee6__4"
      },
      "source": [
        "Configurações IA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "arLvvIA26_NV"
      },
      "outputs": [],
      "source": [
        "# Configurações de geração e segurança\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.7, # Ajuste a temperatura para controlar a criatividade\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V89s3_-u7LsQ"
      },
      "outputs": [],
      "source": [
        "safety_settings = {\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DqPdN2FZ7R46"
      },
      "outputs": [],
      "source": [
        "# Inicializando o modelo gemini-1.0-pro\n",
        "model = genai.GenerativeModel(model_name='models/gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J-NQPV9i7VQg"
      },
      "outputs": [],
      "source": [
        "# Iniciando um chat\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hv9G71Zv7Z6q"
      },
      "outputs": [],
      "source": [
        "# Dicionário para armazenar histórico de interações por cidade\n",
        "historico_interacoes = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código para gerar as respostas como NPC para uso em mesas de RPG"
      ],
      "metadata": {
        "id": "d0f2T6nD3GAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta_ia(prompt, persona, cidade, nome_aventureiro, chat):\n",
        "  \"\"\"Gera uma resposta usando o modelo PaLM 2, considerando o histórico.\n",
        "\n",
        "  Args:\n",
        "    prompt: A pergunta ou declaração do usuário.\n",
        "    persona: A personalidade que a IA deve assumir.\n",
        "    cidade: A cidade onde a interação ocorre.\n",
        "    nome_aventureiro: O nome do aventureiro.\n",
        "    chat: O objeto de chat do modelo.\n",
        "\n",
        "  Returns:\n",
        "    A resposta gerada pela IA.\n",
        "  \"\"\"\n",
        "  historico = historico_interacoes.get(cidade, {}).get(nome_aventureiro, \"\")\n",
        "\n",
        "  # Verifica se o jogador está perguntando sobre itens\n",
        "  if any(keyword in prompt.lower() for keyword in [\"itens\", \"armas\", \"armaduras\", \"suprimentos\"]):\n",
        "      instrucao_itens = \"Lembre-se de incluir as características de jogo entre parênteses quando descrever itens e seus preços.\\nExemplo: Espada Curta (1d6 de dano cortante) (10 peças de ouro)\\n\"\n",
        "  else:\n",
        "      instrucao_itens = \"\"\n",
        "\n",
        "  prompt_completo = f\"\"\"Você é um {persona} em um mundo de fantasia medieval na cidade de {cidade}.\n",
        "  {instrucao_itens}{historico} {nome_aventureiro}: {prompt}\"\"\"\n",
        "\n",
        "  resposta = chat.send_message(prompt_completo)\n",
        "  texto_resposta = resposta.text\n",
        "\n",
        "  time.sleep(8) #Timer pois estava sofrendo com erros da API relacionados a muitas chamdas seguidas\n",
        "\n",
        "  # Gera anedota aleatória se for o taverneiro\n",
        "  if persona == \"taverneiro medieval\" and random.random() < 0.2: # 20% de chance de contar uma anedota\n",
        "    prompt_anedota = f\"Conte uma anedota engraçada que um taverneiro medieval contaria na cidade de {cidade}.\"\n",
        "    anedota = chat.send_message(prompt_anedota).text\n",
        "    texto_resposta += f\"\\n\\nEnquanto isso, ouvi uma história interessante...\\n{anedota}\"\n",
        "\n",
        "  historico_interacoes.setdefault(cidade, {})[nome_aventureiro] =  f\"{historico} {nome_aventureiro}: {prompt} {persona}: {texto_resposta}\"\n",
        "\n",
        "  return f\"\\033[32m{texto_resposta}\\033[0m\" # Texto em verde"
      ],
      "metadata": {
        "id": "mVBL3ZDH1YQq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot"
      ],
      "metadata": {
        "id": "VFErjXof3ODW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qvXOLowYzrk7",
        "outputId": "8e71529a-869b-41cb-cbd0-e5a8215cba0f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1a4e51c60876>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loop principal do chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnome_aventureiro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Qual o seu nome, aventureiro? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcidade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Em qual cidade você inicia sua jornada? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpersona\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Variável para armazenar a persona atual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Loop principal do chatbot\n",
        "nome_aventureiro = input(\"Qual o seu nome, aventureiro? \")\n",
        "cidade = input(\"Em qual cidade você inicia sua jornada? \")\n",
        "persona = None  # Variável para armazenar a persona atual\n",
        "\n",
        "while True:\n",
        "  print(f\"\\nVocê está em {cidade}.\")\n",
        "\n",
        "  if persona is None:  # Se não estiver conversando com ninguém\n",
        "    print(\"\\nQuem você gostaria de encontrar? Escolha entre:\")\n",
        "    print(\"1. Mercador\")\n",
        "    print(\"2. Taverneiro\")\n",
        "    print(\"3. Soldado\")\n",
        "    print(\"4. Trocar de Cidade\")\n",
        "    print(\"0. Sair\")\n",
        "\n",
        "    escolha = input(\"Digite o número da sua escolha: \")\n",
        "\n",
        "    if escolha in ['1', '2', '3']:\n",
        "      persona = {\n",
        "          '1': \"mercador medieval\",\n",
        "          '2': \"taverneiro medieval\",\n",
        "          '3': \"soldado medieval\",\n",
        "      }[escolha]\n",
        "    elif escolha == '4':\n",
        "      cidade = input(\"Digite o nome da nova cidade: \")\n",
        "    elif escolha == '0':\n",
        "      print(\"Adeus, aventureiro!\")\n",
        "      break\n",
        "    else:\n",
        "      print(\"Escolha inválida. Tente novamente.\")\n",
        "\n",
        "  # Interação com o NPC (se persona não for None)\n",
        "  if persona is not None:\n",
        "    prompt = input(f\"O que você gostaria de dizer ao {persona}? \")\n",
        "    if prompt.upper() == \"SAIR\":\n",
        "      persona = None  # Reseta a persona ao digitar SAIR\n",
        "    else:\n",
        "      resposta = gerar_resposta_ia(prompt, persona, cidade, nome_aventureiro, chat)\n",
        "      print(f\"{persona}: {resposta}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORyHilNDNJlnOB63QCCcVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}